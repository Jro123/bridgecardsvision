import pytesseract
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoTokenizer
import numpy as np
import cv2

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
if device.type == 'cuda':
    print("CUDA is being used.")
else:
    print("CUDA is not being used.")
    
pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Remplacez par le chemin correct
processor = None
model = None
tokenizer = None

def preprocess_image(image):
    image_resized = cv2.resize(image, (384, 384))
    inputs = processor(images=image_resized, return_tensors="pt")
    pixel_values = inputs['pixel_values'].to(device)
    if pixel_values.dim() == 3:
        pixel_values = pixel_values.unsqueeze(0)
    return pixel_values
def reconnaitre_caractere_et_orientation(image, rotation=False):
    if rotation:
        image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)
    scale = 8  # Augmenter la taille de 800%
    width = int(image.shape[1] * scale)
    height = int(image.shape[0] * scale)
    dim = (width, height)
    resized_image = cv2.resize(image, dim, interpolation=cv2.INTER_LINEAR)

    gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)
    thresh_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
    custom_config = r'--oem 3 --psm 10'

    orientation_angle = 0
    text = pytesseract.image_to_string(thresh_image, config=custom_config)
    print("Texte reconnu:", text)

    return text, orientation_angle 
def process_image(image_bytes, width, height):
  try: 
    print("appel process_image")
    #print(width)
    #print(height)
    image_array = np.frombuffer(image_bytes, dtype=np.uint8).reshape((height, width, 3))
    inputs = preprocess_image(image_array)
    with torch.no_grad():
        outputs = model.generate(inputs, return_dict_in_generate=True, output_scores=True)
        generated_ids = outputs.sequences
        text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        logits = outputs.scores
        confidence_scores = [torch.softmax(logit, dim=-1) for logit in logits]
        avg_confidence_score = np.mean([score.max().item() for score in confidence_scores])
 
    ocr_text, orientation = reconnaitre_caractere_et_orientation(image_array)
    if ocr_text != '' and ocr_text[0] == text[0]:
        orientation = 360  # pour distinguer de zéro pour non déterminé
    else:
        print('rotation')
        ocr_text, orientation = reconnaitre_caractere_et_orientation(image_array, rotation=True)
        if ocr_text != '' and ocr_text[0] == text[0]:
            orientation = 90
    result = f"{avg_confidence_score},{text},{orientation}"
    print(result)
    return result
  except Exception as e:
        print(f"Erreur dans process_image : {e}")
def chargerModele():
    global processor
    global model
    global tokenizer
    nom = 'microsoft/trocr-base-printed'
    processor = TrOCRProcessor.from_pretrained(nom)
    tokenizer = AutoTokenizer.from_pretrained(nom)
    model = VisionEncoderDecoderModel.from_pretrained(nom).to(device)

# Charger le modèle une fois au démarrage
chargerModele()
